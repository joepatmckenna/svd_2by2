download.packages('knitr')
q()
install.packages('caret')
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
setwd('~/Dropbox/data_science/08_practical_machine_learning/project')
library(caret)
training <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
testing <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
setwd('~/Dropbox/data_science/08_practical_machine_learning/project')
library(caret)
training <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
# store last columns of training and testing sets
class <- training$classe
problem_id <- testing$problem_id
# remove columns from training and testing sets
training <- training[,-c(seq(7), dim(training)[2])]
testing <- testing[,-c(seq(7), dim(testing)[2])]
# plot histograms of the feature data sparsity
column_sparsity <- function(X) {
apply(X, 2, function(col){mean(is.na(col))})
}
training_sparsity = column_sparsity(training)
testing_sparsity = column_sparsity(testing)
par(mfrow=c(1,2))
hist(training_sparsity, main='Sparsity of training data features', xlab='feature data sparsity')
hist(testing_sparsity, main='Sparsity of testing data features', xlab='feature data sparsity')
# subset training and testing sets to only include features with dense data
dense_features = training_sparsity <.5 & testing_sparsity < .5
dense_features = names(which(dense_features))
training = training[,dense_features]
testing = testing[,dense_features]
#fit <- train(class~., data=training, method='gbm')
mean(complete.cases(training))
mean(complete.cases(testing))
head(class)
? confusionMatrix
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
setwd('~/Dropbox/data_science/08_practical_machine_learning/project')
library(caret)
training <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
testing <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
# store last columns of training and testing sets
class <- training$classe
problem_id <- testing$problem_id
# remove columns from training and testing sets
training <- training[,-c(seq(7), dim(training)[2])]
testing <- testing[,-c(seq(7), dim(testing)[2])]
# plot histograms of the feature data sparsity
column_sparsity <- function(X) {
apply(X, 2, function(col){mean(is.na(col))})
}
training_sparsity = column_sparsity(training)
testing_sparsity = column_sparsity(testing)
par(mfrow=c(1,2))
hist(training_sparsity, main='Sparsity of training data features', xlab='feature data sparsity')
hist(testing_sparsity, main='Sparsity of testing data features', xlab='feature data sparsity')
# subset training and testing sets to only include features with dense data
dense_features = training_sparsity <.5 & testing_sparsity < .5
dense_features = names(which(dense_features))
training = training[,dense_features]
testing = testing[,dense_features]
accuracy <- function(prediction, actual) {
mean(actual==prediction)
}
training = data.frame(cbind(training, class))
# folds <- createFolds(y=training$class, k=4, list=TRUE, returnTrain=TRUE)
in_training <- createDataPartition(y=training$class, p=0.6, list=FALSE)
training_training <- training[in_training,]
training_testing <- training[-in_training,]
fit <- train(class~., data=training_training, method='rf')
install.packages('e1071')
accuracy <- function(prediction, actual) {
mean(actual==prediction)
}
training = data.frame(cbind(training, class))
# folds <- createFolds(y=training$class, k=4, list=TRUE, returnTrain=TRUE)
in_training <- createDataPartition(y=training$class, p=0.6, list=FALSE)
training_training <- training[in_training,]
training_testing <- training[-in_training,]
fit <- train(class~., data=training_training, method='rf')
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
setwd('~/Dropbox/data_science/08_practical_machine_learning/project')
library(caret)
training <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
testing <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
# store last columns of training and testing sets
class <- training$classe
problem_id <- testing$problem_id
# remove columns from training and testing sets
training <- training[,-c(seq(7), dim(training)[2])]
testing <- testing[,-c(seq(7), dim(testing)[2])]
# plot histograms of the feature data sparsity
column_sparsity <- function(X) {
apply(X, 2, function(col){mean(is.na(col))})
}
training_sparsity = column_sparsity(training)
testing_sparsity = column_sparsity(testing)
par(mfrow=c(1,2))
hist(training_sparsity, main='Sparsity of training data features', xlab='feature data sparsity')
hist(testing_sparsity, main='Sparsity of testing data features', xlab='feature data sparsity')
# subset training and testing sets to only include features with dense data
dense_features = training_sparsity <.5 & testing_sparsity < .5
dense_features = names(which(dense_features))
training = training[,dense_features]
testing = testing[,dense_features]
training = data.frame(cbind(training, class))
# folds <- createFolds(y=training$class, k=4, list=TRUE, returnTrain=TRUE)
# cm_tab <- confusionMatrix(prediction, training_testing$class)$table
accuracy <- function(prediction, actual) {
mean(actual==prediction)
}
in_training <- createDataPartition(y=training$class, p=0.6, list=FALSE)
training_training <- training[in_training,]
training_testing <- training[-in_training,]
model_fit <- train(class~., data=training_training, method='glm')
model_fit <- train(class~., data=training_training, method='rf')
?train
# folds <- createFolds(y=training$class, k=4, list=TRUE, returnTrain=TRUE)
# cm_tab <- confusionMatrix(prediction, training_testing$class)$table
accuracy <- function(prediction, actual) {
mean(actual==prediction)
}
in_training <- createDataPartition(y=training$class, p=0.6, list=FALSE)
training_training <- training[in_training,]
training_testing <- training[-in_training,]
model_fit <- train(class~.,
data=training_training,
method='rf',
trControl=trainControl(number=4, allowParallel=TRUE))
library(doMC)
install.packages('doMC')
library(doMC)
registerDoMC(cores=6)
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
setwd('~/Dropbox/data_science/08_practical_machine_learning/project')
library(caret)
library(doMC)
registerDoMC(cores=6)
# folds <- createFolds(y=training$class, k=4, list=TRUE, returnTrain=TRUE)
# cm_tab <- confusionMatrix(prediction, training_testing$class)$table
accuracy <- function(prediction, actual) {
mean(actual==prediction)
}
in_training <- createDataPartition(y=training$class, p=0.6, list=FALSE)
training_training <- training[in_training,]
training_testing <- training[-in_training,]
model <- train(class~.,
data=training_training,
method='rf',
trControl=trainControl(number=4, allowParallel=TRUE))
prediction <- predict(model, newdata=training_testing)
print(accuracy(prediction, training_testing$class))
x<-training
dim(x)
training[0,0]
training[[0,0]]
training[[0]][[0]]
training[[0]]
training[0,0]
training[1,1]
x[1,1]
x[1,1]<-0
x[1,1]
training[1,1]
problem_id
confusionMatrix(prediction, training_testing$class)
confusionMatrix(prediction, training_testing$class)$table
# predict on testing partition of training data
prediction <- predict(model, newdata=training_testing)
# print accuracy
accuracy <- function(prediction, actual) {
mean(actual==prediction)
}
print(accuracy(prediction, training_testing$class))
# print confusion matrix
print(confusionMatrix(prediction, training_testing$class)$table)
prediction <- predict(model, newdata=testing)
head(prediction, 20)
# print responses for prediction quiz portion
prediction <- predict(model, newdata=testing)
head(prediction, 20)
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, cache=TRUE)
setwd('~/Dropbox/data_science/08_practical_machine_learning/project')
library(caret)
# print confusion matrix
print(confusionMatrix(prediction, training_testing$class)$table)
summary(training)
names(training)
x<-prcomp(training)
?prcomp
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, cache=TRUE)
setwd('~/Dropbox/data_science/08_practical_machine_learning/project')
library(caret)
set.seed(1234)
# make copy of downloaded sets
training <- TRAINING
#You should create a report describing how you built your model
#how you used cross validation
#what you think the expected out of sample error is
#why you made the choices you did
TRAINING <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
TESTING <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
# make copy of downloaded sets
training <- TRAINING
testing <- TESTING
# store training labels as its own vector
class <- training$classe
# remove columns from training and testing sets
training <- training[,-c(seq(7), dim(training)[2])]
testing <- testing[,-c(seq(7), dim(testing)[2])]
# plot histograms of the feature data sparsity
column_sparsity <- function(X) {
apply(X, 2, function(col){mean(is.na(col))})
}
training_sparsity = column_sparsity(training)
testing_sparsity = column_sparsity(testing)
par(mfrow=c(1,2))
hist(training_sparsity, main='Sparsity of training data features', xlab='feature data sparsity')
hist(testing_sparsity, main='Sparsity of testing data features', xlab='feature data sparsity')
# subset training and testing sets to only include features with dense data
dense_features = training_sparsity <.5 & testing_sparsity < .5
dense_features = names(which(dense_features))
training = training[,dense_features]
testing = testing[,dense_features]
names(training)
mean(complete.cases(training))
x<-prcomp(training)
x<-prcomp(training, center=TRUE, scale.=TRUE)
training_pca <- prcomp(training, center=TRUE, scale.=TRUE)
print(training_pca)
training_pca$rotation
dim(training_pca$rotation)
names(training_pca$rotation)
dim(training_pca$rotation)
training_pca$x
dim(training_pca$x)
pca <- prcomp(training, center=TRUE, scale.=TRUE)
training_pca <- predict(pca, newdata=training)
View(training_pca)
dim(training_pca)
dim(training_pca[,c(1,2)])
plot(training_pca[seq(100),c(1,2)])
plot(training_pca[,c(1,2)])
plot(training_pca[,c(1,2)])
?plot
plot(training_pca[,c(1,2)], col=class)
pca <- prcomp(training, center=TRUE, scale.=TRUE)
training_pca <- predict(pca, newdata=training)
plot(training_pca[,c(1,2)], col=class)
head(class)
?folds
??folds
?train
print(model)
model$modelInfo
model$results
model$results['Accuracy']
mean(model$results['Accuracy'])
mean(model$results['Accuracy'])
model$results['Accuracy']
dim(model$results['Accuracy'])
model$results['Accuracy'][,1]
mean(model$results['Accuracy'][,1])
print(model)
install.packages('plotly')
knitr::opts_chunk$set(echo = FALSE)
library(plotly)
library(httr)
install.packages('httr')
install.packages('curl')
install.packages('libcurl')
install.packages('plotly')
install.packages('plotly')
library(plotly)
plot_ly(mtcars, x=wt, y=mpg, mode='markers')
library(plotly)
data("mtcars")
plot_ly(mtcars, x=wt, y=mpg, mode='markers')
library(plotly)
load("mtcars")
library(plotly)
plot_ly(data=mtcars, x=wt, y=mpg, mode='markers')
library(plotly)
plot_ly(mtcars, x=wt, y=mpg, mode='markers')
?mtcars
library(plotly)
plot_ly(mtcars, x = wt, y = mpg, mode='markers')
library(plotly)
mtcars
names(mtcars)
library(plotly)
plot_ly(mtcars, x = 'wt', y ='mpg', mode='markers')
library(plotly)
plot_ly(mtcars, x=wt, y=mpg, mode='markers')
library(plotly)
plot_ly(x=wt, y=mpg, data=mtcars, mode='markers')
?plot_ly
library(plotly)
plot_ly(data=mtcars, x=wt, y=mpg, mode="markers")
library(plotly)
plot_ly(data=mtcars, x=wt, y=mpg, mode="markers")
library(plotly)
plot_ly(data=mtcars, x=mtcars$wt, y=mtcars$mpg, mode="markers")
library(plotly)
plot_ly(x=mtcars$wt, y=mtcars$mpg, mode="markers")
library(plotly)
plot_ly(x=mtcars$wt, y=mtcars$mpg, mode='markers', color=as.factor(mtcars$cyl), size=mtcars$hp)
library(plotly)
plot_ly(x=mtcars$wt, y=mtcars$mpg, mode='markers', color=as.factor(mtcars$cyl), size=mtcars$hp, xlab='Weight')
library(plotly)
plot_ly(x=mtcars$wt, y=mtcars$mpg, mode='markers', color=as.factor(mtcars$cyl), size=mtcars$hp)
knitr::opts_chunk$set(echo=FALSE, warning = FALSE, message = FALSE)
install.packages('shiny')
install.packages("shiny")
library(shiny)
runApp('Dropbox/data_science/09_developing_data_products/dc_condos')
setwd("~/Dropbox/data_science/09_developing_data_products/dc_condos")
runApp()
runApp()
setwd("~/Dropbox/data_science/09_developing_data_products/dc_condos")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?svd
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages('MathJax')
install.packages('mathjax')
install.packages('mathJax')
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
[[1,2],[3,4]]
c(c(1,2),c(3,4))
rbind(c(1,2),c(3,4))
x<-rbind(c(1,2),c(3,4))
x
svd(x)
plot(c(1,1))
plot(c(1,1), type='line')
plot(c(0,0), c(1,2), type='l')
plot(c(0,0), c(1,2), type='line')
plot(c(0,0), c(1,2), type='line')
plot(c(1:5), c(1:5), type='l')
plot(c(0,0), c(1,2), type='l')
plot(x=c(0,0), y=c(1,2), type='l')
plot(x=c(0,1), y=c(0,2), type='l')
?svd
runApp()
runApp()
runApp()
runApp()
runApp()
x <- rbind(c(1,-2),c(-2,1))
x
s <- svd(x)
s
plot(c(0,s$u[1,1]), c(0,s$u[2,1]))
plot(c(0,s$u[1,1]), c(0,s$u[2,1]), type='l')
lines(c(0,s$u[1,2]), c(0,s$u[2,2]))
max(u)
max(s$u)
abs(s$u)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
round(1.2334455566)
round(1.2334455566, 2)
runApp()
runApp()
runApp()
runApp()
runApp()
